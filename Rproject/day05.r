### 통계학 추정
# 통계학을 배우는 이유? 
# 통계학에서 실제 전체 집단에 대한 특성을 알고 싶을 때, 그게 현실적으로 가능할까?
# 답은 어렵다. 실제로 전체 집단에 대한 자룔를 구한다는 것은 쉽지 않은 일이란 점이다...
# 집단 전체가 아닌 일부 표본집을 집단을 통해서 전체에 대해서 추론을 하는 것이다.
### 예시) 선거철 여론조사
### 이런 이유로 우리는 올바른 통계적 추론 방법을 사용하는 것이 매우 중요합니다.

### 통계적 추정의 종류
# 통계학에서 모집단(population)과 표본(sample)을 구분한다.
#
# - 모집단은 우리가 여러번 언급한 관심을 가진 전체 집단
# - 표본은 모집단의 일부를 의미합니다. 여기서 표본이란(random sample)을 말함.
#  임의표본은 모집단의 모든 구성원에게 표본에 포함될 기회를 똑같이 주고 출출한 표본,
#  그리고, 특정 단위가 선택될 확률은 다른 단위가 선택될 확률과 독립적이다.
#  "독립적이면서도 동일하게 분포된(independent and identically distributed - iid)"
#  라고 표현합니다.

# 모집단에서 표본을 업드면, 그것을 바탕으로 모집단에 대해서 추정하는데,
# 통계적 추론으로 1)정추정(point estimation)과 2)구간 추정(interval estimation)이 있다.

## 정추정
# 정추정은 관심을 갖고 있는 숫자, 이를테면 모집단의 평균, 비율 등과 같이 하나의 숫자로
# "찍는" 것을 말합니다.
#   모집단의 평균과 비울을 모평균, 모비율로 말하는 방식으로 모집단으 수치를 표시한다.
# 같은 방식으로 표본집단의 평균도 모본평균, 표본비율이라고 부릅니다. 
# 모집단의 특정 값을 알기 위해서는 표본에서 같은 특정 값을 사용하여 추정하는 것이 맞다.
# 그래서 표본집단의 특정값 예로 평균을 정추정하여 모집단의 평균을 구하는 것이다.
### 예시, "한국의 20대 여성"이라는 모집단의 키 평균을 추정한다면, 100의 표본을 추출하여
### 키의 표준평균을 계산한 다음, 그것을 모평균의 추정치로 사용하는 방식.
### 같은 방식으로 모비율에 대한 추정, 표준편차에 대한 추정도 가능하다.

### 표집오차(sample error)
# 모집단에서 임의표본을 추출한다는 것은 각기의 단위에 뽑힐 기회가 무작위적으로 주어진다는
# 것을 뜻한다. 이는 추출할 때마다 표본이 달라지고 표본의 평균이나 표본비율도 달라질수 있다.
# 이런 현상을 통계학에서는 "표집오차(sample error)"라고 합니다.
# 이 표집오차로 인해서 표본의 평균, 비율을 일치하지 않을 경우가 대부분인 것을 알 수 있다.
# 하지만, 일치하지 않는 정도는 어떤 범위 내로 정해져 있을 것이다. 
# 이 정도를 표준오차(standard error)라고 부릅니다.
# 이 표준오차가 작은 추정방식일수록 좋은 추정 방식이 된다.

## 구간추정
# 위에서 말한 표준오차를 알고 있다면, 구간추정을 할 수 있습니다.
# 정추정의 하나의 숫자를 찍는 것과 달리 구간추정은 모수치가 대략 어디에서 어디 사이에
# 있을 것이라고 예상하게 해줍니다.
# 예로 선거에서 특정 후보의 지지율을 단순히 40%라고 하지않고, 38.5 ~ 43.5% 에 있다고
# 하는 경우를 구간추정이라고 볼 수 있다. 정추정과 다른 점은 하나의 숫자를 전달하는게 아닌
# 불확실성의 정도를 함께 전달하고 있어서 더 바람직한 경우가 많다는 점이다.
# 여기서 "신뢰구간" 또는 "신뢰도"라는 말했다면, 보통 구간 추정을 했다는 의미입니다.

## 모평균의 추정
# 표본평균은 모평균에 대해서 즐겨 사용한 점추정치로 여러가지 좋은 성질을 가지고 있다.
# 1)불편성(unbiasedness)
#  모집단에서 추출을 계속하면서 표본평균을 계산한다면, 그 기댓값은 모 평균에 일치합니다.
# 예로 앞에서 예기한 "20대 한국 여성"이라는 모집단의 키의 평균을 구하는 것을 생각해보자
# 이미 키의 평균은 정해져 있을 것이지만, 우리는 정확히 알지 못한다면,
# 모집단에서 임의의 100명씩 표본을 추출하여 평균을 계산하는 것을 반복합니다.
# 그리고, 표본을 100은 평균을 계산한 다음에 다시 모집단으로 돌려보냅니다.
# 즉, 복원추출을 한다는 의미입니다. 이렇게 1000번 반복한 다음에 이 1000개의 표본평균을 얻을 수 있습니다.
# 그리고, 이 값들의 평균을 구하면, 이것이 바로 평균의 평균입니다.
#  불편성은 이렇게 평균을 한 없이 모으면 그 값들의 평균은 모평균과 일치한다는 것을 말함.
# 불편성은 표본평균을 모평균에 대한 추정치로 사용할 때에 모평균에 비해 작거나 큰 값으로
# 치우치는 경향이 없다는 것을 보장한다는 것입니다. 이 추정치를 불편추정치 라고 합니다.
# 반면, 음이나 양의 방향으로 치우치는 경향이 있는 추정치를 "편의 추정치"라고 합니다.

# 2)최소분산(minimum variance)
# 표본평균 말고도 모평균에 대해 불편추정치를 만들 수 있는데, 자료를 많이 모았다고 하더라도
# 그 중 첫번째 값만 때에 모평균에 대한 추정치로 사용할 수 있습니다. 그러면 그 기대값이나
# 평균은 모평균과 같을 수 있습니다. 하지만, 이런 방식은 표본평균에 비해 변동성이 훨씬 크다
# 수학적인 증명이 있으나 여기서는 단순히 자료으 수가 적으면 정보의 양도 적다는 것을 의미함.
# 위에 이야기한 표본평균은 모평균에 대한 불편추정치 중 변동성이 가장 작습니다.
# 모평균과 가장 가깝다는 의미고, 이것이 "최소 분산"의 의미가 됩니다.
# 여기서 분산은 변동성을 측정하는 단위의 하나라고 이해하면 된다.

### R을 이용한 표본평균 시뮬레이션하기
# 불편성은 직접 시뮬레이션을 하지 않으면 이해하기가 쉽지 않는 개념입니다.
# 모집단이 특정 사료가 아니라 확률분포라고 가정합니다.
# 확률분포는 자료가 무한히 많은 모집단처럼 간주하기도 합니다.
# 평균이 170이고,, 표준편차가 15인 확률분포, N(170,15^2)을 모집단으로 생각합니다.
# 이것은 어떤 가상 집단의 키의 분포라고 생각할 수 있다.
# 이 모집에서 표본평균을 추출작업을 반복하여 값을 구합니다.

# 난수 생성기 시드 고정
set.seed(1234)      # 참고 : 시드 값은 아무거나 넣어도 상관없음. 대신 같은 값이면 고정된 결과

# 표본평균 개수
n_sim <- 10000

# 각 표본의 크기
sample_size <- 100

# 백터 생성
means <- c()

for (i in 1:n_sim) {
    data <- rnorm(sample_size, 170, 15)
    means <- c(means,mean(data))
}

hist(means,xlab = "X", ylab = "Y", main="",prob=T,breaks=50)

curve(dnorm(x,170,15 / sqrt(sample_size)), 160,180,add=T, lty=2 , lwd=2 ,col="red")

# 출력된 그래프를 확인하면, 완벽하지는 않지만, 표본평균의 분포는 대충 종형곡선에 가까운
# 것을 확인할 수 있습니다.
# 이것은 앞에서 말한 표본평균의 분포는 정규분포를 따른다는 "중심극한 정리"의 결과입니다.
# 시뮬레이션 횟수를 더 늘리면 곡선이 실제 자료에 점점더 잘 들어 맞게 됩니다.
# 통계학에서는 "fit이 좋아진다"고 합니다.
# 이 분포의 표준편차는 모집단의 표준편차인 15를 표본의 크기인 100의 제곱근, 즉 10으로
# 나눈 것과 같습니다.(표준오차) 일반적으로 표본평균의 표준편차는 모집단의 표준편차에 비해
# "표본의 크기의 제곱근"의 역배수만큼 작습니다. 즉, 여기서는 표본평균의 표준편차는 1.5가 됩니다.
# 실질적으로 모표준편차를 모르기 때문에 다른 방식으로 추정한 뒤에 그것을 대신 사용합니다.

# 이 시뮬레이션을 하기 전에 표본평균은 모평균의 대한 불편추정치라고 했습니다.
# 이게 사실이면 표본평균의 평균은 모평균에 매우 가까워야 한다.

# 위 시뮬레이션에서 표본평균의 편균을 구하면
mean(means)
# [1] 170.0066 
# 으로 표본평균의 평균은 모평균과 거의 일치하는 것을 확인할 수 있다.

# 또한, 정규분포는 매우 유용한 성질을 가지고 있다고 했습니다.
# 평균에서 +-(2 x 표준편차) 영역 안에 95% 가량의 자료가 포함된다는 것입니다.
# 여기서 표본평균의 경우에도 (2 x 표준오차) 라고 할 수 있습니다.

se = 15/sqrt(sample_size) # standard error
means_within_2se <- (means > 170 - 2*se) & (means < 170 + 2*se)
sum(means_within_2se)
# [1] 9514

# standard error는 표준편차를 각 표본의 크기에 대한 루트값으로 나눈 것입니다.
# 위에서 계산한 값이 1.5가 나옵니다.

# 두번째, 표본평균이 위에 170 +-(2 x 표준오차) 안에 포함되는지 여부를 각각 알아본 뒤에
# means_within_2se에 저장하고 있습니다. 이때에 결과가 TRUE 또는 FALSE가 저장됩니다.
# 각각의 TURE는 1로, FALSE는 0으로 취급되고, 이들의 합을 구하면 전체 시행 횟수에 따라
# 얼마나 TRUE가 나왔는지를 알 수 있게 됩니다. 그리고 그 값은 95.14%로 95%라는 값과
# 대략 일치하는 것을 알 수 있다.

### 모평균에 대한 구간추정
# 표본평균이 정규분포를 따른가는 것은 수학적 증명이 시뮬레이션으로 확인했습니다.
# 이것을 통계학적으로 표현하면, 자료가 평균이 m, 표준편차가 s인 어떤 분포를 따른다고 한다면,
# 이 분포의 크기인 n이 표본을 추출하여 표본평균을 구하는 일을 반복할 때,
# n이 커짐에 따라 표본평균은 근사적으로 다음과 같은 정규분포를 따른 것으로 알려져 있습니다.

# N(m, s*2/n)
# 표본평균으 ㅣ분산, s^2/n은 자료의 크기에 반비례하여 작아집니다.
# 이 사실을 활용하여 다음이 성립할 수 있다.

# 원래는 X 위에 바를 그어서 표현하나, 지금은 그냥 대문자 x로 표현 - 표본평균

# P(m - 2 x s/sqrt(n)) < X < m + 2 x s/sqrt(n) -> 0.95
# 이것은 표본평균이 모평균으로부터 +-(2 x 표준오차)안에 있을 확률은 95%이다 를
# 수학적으로 표현한 것입니다.

# 첫번째 부등식 m - 2/sqrt(n) < X ,m 이하의 부분을 넘기면
# m < X + 2 x s/sqrt(n)

# 두번째 부등식, X < m + 2/sqrt(n) 도 첫번째와 같은 방식으로 처리하면,
# m > X - 2 x s/sqrt(n)

# 첫번째, 두번째 부등식의 결과를 합치면,
# X - 2 x s/sqrt(n) < m  < X + 2 x s/sqrt(n)

# P(X - 2 x s/sqrt(n) < m  < X + 2 x s/sqrt(n)) ~= 0.95

# 여기서 "무작위"인 것 즉 표본을 추출할 때 마다 달라지는 것은 모평균이 아닌 표본평균
# 임을 주목합니다. 즉, 위에 평균 m이고, 표준편차가 s인 모집단의 표본평균을 계속 모으면
# 그 중 95%에서 m은 평균에서 (2x표준오차)안에 들어온다는 것을 의미하게 됩니다.

# 신뢰구간은 이와같이 표본평균 +-(2x표준오차)는 모평균에 대한 95% 신뢰구간이라고 합니다.
# 이것은 달리 말하면, 모집단에서 계속 표집하면서 95% 신뢰구간을 만들면, 그 중에
# 95%가 모평균을 포함한다는 것을 의미하게 된다.


# R로 95% 신뢰구간의 성질 확인하기

# 난수 생성기 시드 고정
set.seed(1234)

# 표본평균 개수
n_sim <- 10000

# 각 표본의 크기
sample_size <- 10000
m <- 170
s <- 5
se = s/sqrt(sample_size)
X_bar_in_CI <- c()

# 정규분포에서 표집 후 평균을 저장
for (i in 1:n_sim){
    data <- rnorm(sample_size,m,s)
    X_bar <- mean(data)
    if((X_bar - 2 * se < m ) & (X_bar + 2 * se > m )){
        X_bar_in_CI <- c(X_bar_in_CI, TRUE)
    }else{
        X_bar_in_CI <- c(X_bar_in_CI, FALSE)
    }
}

# 신뢰구간 안에 모평균이 포함된 비율
mean(X_bar_in_CI)

## 계산 값을 확인하면 95%에 가까운 숫자가 나옵니다.
## 작성한 신뢰구간, (X_bar - 2 * se, X_bar + 2 * se)가
## 실제로 95%의 경우에 모평균을 포함한다는 것을 확인해주는 결과입니다.

### 신뢰구간의 사용에 대한 팁
# - 지금까지 이야기한 모평균에 대한 95% 신뢰구간은 표본평균에 대해 대칭
#    따라서 양 끝 값을 더한 뒤 2 로 나누면 표본평균이 얼마인지 알 수 있다.
#
# - 신뢰도(앞서 이야기 95% 신뢰구간)가 높아질 수록 구간의 길이는 길어집니다.
#  높은 확률로 모평균을 잡아내려면 신뢰구간을 넓게 잡아야 그 안에 떨어질 확률이
#  높아질 것입니다. 하지만, 신뢰구간의 길이기 길수록 신뢰구간 자체의 유효성은 떨어진다.
#  즉, 신뢰가 높다고해서 꼭 좋은 것은 아니다.
#
# - 신뢰도를 추정할 때 표본크기가 커질수록 신뢰구간의 길이는 짧아집니다.
#  수학적으로 신뢰구간의 길이는 표준오차에 비례하게 된다. 모평균에 대한 95% 신뢰구간의 경우
#  대략 (4 x 표준오차) 정도 됩니다. 그런데 표준오차 자체가 모표준편차를 sqrt(n)으로 나눈 것이고,
#  n이 커질수록 표본오차가 작아지기 때문에 결국 신뢰구간의 길이도 짧아지게 된다.
#  객관적으로 표본크기를 늘릴 수록 신뢰구간의 길이는 짧아지게 되고,
#  이는 더 정밀한 구간 추정을 할 수 있다는 의미가 됩니다.
#   하지만, 표본크기를 늘리는 것은 돈과 그 밖에 지원문제가 생기기 때문에 적당한 선에서
#  타협할 수 밖에 없다.

#### 부트스트렙
# 현대 통계학자들이 진보된 계산 기술을 받아들여 기존 수학 공식을 이용한 방식이 잘 통하지 
# 않는 경우에 폭 넓게 적용할 수 있는 보다 강력한 추론 기법을 의미함.
#  부트스트랩을 활용하면 앞에서 살펴봤던 신뢰구간 공식이든 뭐든 전혀 사용하지 않고,
# 컴퓨터 시뮬레이션만으로도 평균을 추정하고, 신뢰구간을 만들 수 있습니다.

## 부트스트랩 원리
# 앞서서 관심을 가진 모집단, "20대 한국 남성"이란 모집단에 전수 자료에 접근할 수 없기 떄문에
# 표본을 추출하고, 그것을 가지고 통계적 추정을 한다고 이야기 했습니다.
# 모집단의 대한 특정 가정하에서 표본을 계속 추출한다고 했을 때 실제로 관측한 표본이
# 그중에 어느 위치에 있는지를 생각했습니다.
# * 이런 발상을 전환하여 우리가 갖고 있는 표본 자체가 일종의 모집단인 것처럼 여길수는 없을까?
# 이 가정을 받아들이면 그 가상의 모집단에서 계속 표본을 추출하여 평균을 계산하고
# 그것들을 모아 분포를 만들 수 있을 것입니다.
# 이것은 우리 컴퓨터로 지금까지 했던 방식으로 쉽게 할 수 있는 작업입니다.
# 이것이 바로 부트스트랩 방식입니다.

## 부트스트랩 장점
# 추정에 필요한 수학공식을 모르거나 애초에 존재하지 않아도 관심이 있는 대상, 즉 평균이나
# 중앙값등에 대한 분포를 만들고 신뢰구간도 만들 수 있습니다.
# 앞서 시뮬레이션 방식을 이용하며 만들게 됩니다.
#  표본평균의 경우 표본평균이 중심극한정리에 의해 근사적으로 정규분포에 따른다는 점을
# 이용하여 95% 신뢰구간을 만들때, 표본평균 +-(2 x 표준오차) 공식을 사용했다.
# 이것은 중심극한 정리가 적용되지 않는 대상, 또는 구간 추정공식을 모르는 대상에 대해서는
# 적용할 수 없습니다. 부트스트랩을 사용하면 신뢰구간을 간편하게 얻을 수 있다.

### R에 내장된 데이터세트를 이용하여 부트스트랩 방식을 실습하겠습니다.
### 자료는 붓꽃(iris)
iris
class(iris)
head(iris)

## 부스트스탭으로 모평균 추정하기(자료 : iris)
# iris는 데이터세트로 총 5가지 변수를 가지고 있습니다.
# 150개의 데이터가 각각 꽃잎(petal), 꽃받침(sepal), 각 길이(length)와 너비(width)
# 종 (species)으로 기록된 자료입니다.

# 여기서 종이 setosa종의 꽃잎 길이의 모평균에 대해서 정추정과 구간추정을 해봅니다.
# 꽃잎 길이 변수는 데이터 세트 안에 Petal.Length라는 이름으로 저장되어 있습니다.
# 추정 공식을 사용하면 모평균에 대한 정추정치는 포뵨 평균과 같고, 구간 추정치는 이것에
# (2 x 표준오차)를 더하거나 뺀 것으로 만들 수 있습니다.
# 여기 예제는 sqrt(50)으로 나눈 것과 같습니다.
#  여기서는 한가지 주의할 점이 있습니다. 앞에서 보았던 예제들은 모집단의 표준편차를
# 정확히 안다고 가정했습니다. 지금 setosa종의 모표준편차를 안다고 가정할 수 없다.
# 그러므로 여기서는 표본에서 추정한 표준편차를 사용합니다.
# 정규분포 추정공식을 바로 이용할 수 없다.
# 이렇게 되면 정규분포를 근사하는 분포인 t분포를 사용해야 합니다.
# 하지만 t분포는 펴본크기가 충분히 크면 정규분포에 가까워지고 이를 적용 가능하지만,
# 지금 현재는 관심사가 아닙니다. 정규분포 추정공식을 사용할 것입니다.

# 먼저, setosa종의 자료만 따로 추출하기...
# 이 때에 실행함수는 subset()을 사용합니다. subset() 부분집합을 만들어 저장하는 의미

y <- subset(iris, Species == 'setosa')$Petal.Length

# 이 값들의 평균을 쉽게 구할 수 있습니다. (모평균의 대한 점추정치)
mean(y)
# [1] 1.462

# 다음으로 95% 신뢰구간을 만들어 봅니다. 그럴려면 표준편차를 구해야 한다.
# R은 표준편차(Standard deviation)을 구하는 함수를 가지고 있습니다. 앞글자 따서 sd()
sd(y)
# [1] 0.173664

# 이제 이 값을 당분간 모표준편차 처럼 사용합니다. 그리고, 표준오차를 구하고 신뢰구간을
# 만들려면 다음과 같이 처리합니다.

n <- length(y)
ci_lower <- mean(y) - 2 * sd(y)/sqrt(n)
ci_upper <- mean(y) + 2 * sd(y)/sqrt(n)
print(c(ci_lower, ci_upper))
# [1] 1.41288 1.51112

### 이제 모평균에 대한 구간 추정 공식을 모든다고 치고, 부트스트랩 방식으로 추정(**)
## 앞에서 부트스트랩은 가장의 모집단인 표본에서 반복 추출하는 방식이기 때문에
## 이를 위한 시뮬레이션 코드를 작성해야 합니다.
n_sim <- 10000
means <- c()
for (i in 1:n_sim){
    bs_sample <- sample(y,length(y),replace = T)
    sample_mean <- mean(bs_sample)
    means <- c(means,sample_mean)
}

head(means,12L)

# 여기서 중요한 것은 sample입니다.
# 첫번째 입력값인 y로부터 무작위로 표본추출을 하는데, 그 표본의 크기가 두번째 입력값과
# 같습니다. 여기서 부트스트랩에서 중요한 것은 원자료에서 표본을 추출할 때 정확히 같은
# 크기 만큼 추출해야 한다는 점(***), 세번째로 replace = TRUE로 복원 추출을 해야한다는 것(필수)

# 이렇게 구해진 means를 이용하여 신뢰구간을 만들 수 있다.
# 95% 신뢰구간은 값들을 정렬했을 때 가운데의 95%에 해당하는 값들의 범위를 의미함.
# 이것은 상위, 하위 2.5%에 해당하는 값들을 찾으면, 그것들로 신뢰구간의 상한, 하한을
# 구할 수 있게 됩니다.
# 이때 사용하는 함수가 quantile()입니다.
# 이 함수는 자료를 작은거 부터 큰거 순으로 나열할 때 주어진 비율에 해당하는 값이 무엇인지 알려줍니다.

quantile(means, .025)       # 하위 2.5%를 의미함
quantile(means, .975)       # 상위 2.5%를 의미함

# 결과적으로 95% 신뢰구간인 1.41, 1.51과 거의 일치합니다.
# 부트스트랩은 수학적 공식을 전혀 사용하지 않고, 오로지 컴퓨터와 시뮬레이션의 힘으로
# 추정했다는 것입니다.

## t분포( 모표준편차를 모를 때에 표준정규분포 대신에 사용하는 일종 근사 )
# t분포는 표준정규분포와 매우 비슷합니다. 종형 모양에 가깝고 0에 대해 대칭적이지만,
# 분포끝부분에 더 많은 자료가 흩어져 있다는 것이 특징입니다.
# 이는 꼬리의 두께는 자유도(degree of freedom)에 의해 결정되고 정규분포가 평균과 표준편차
# 두개의 값으로 결정되는 것과 달리 t분포는 자유도만으로 결정된다.
# 자유도는 낮을 수록 꼬리가 두꺼워지고, 높을 수록 얇아져 t분포는 결국 표준정규분포에 가까워지게 된다.
# t분포의 자유도는 표본크기에서 1을 뺀 것, 즉, (n - 1)과 같습니다.
# 이것을 사용하여 다시 95% 구간을 추정할 수 있습니다.
#  t분포의 상한과 하한을 구하기 위해서 qt()를 사용합니다.

y <- subset(iris, Species == 'setosa')$Petal.Length
n <- length(y)

c(mean(y) + qt(.025,df=n-1) * sd(y)/sqrt(n), mean(y) + qt(.975,df=n-1) * sd(y)/sqrt(n))

#       하한     상한
# [1] 1.412645 1.511355

## 부트스트랩으로 모표준편차 추정하기
# 추정 공식을 아직 모르는 대상에 대해서 구간 추정하는 것을 확인합니다. 모표준편차...

y <- subset(iris, Species == 'setosa')$Petal.Length

n_sim <- 10000
sds <- c()

for (i in 1:n_sim){
    bs_sample <- sample(y, length(y), replace = T)
    sample_sd <- sd(bs_sample)
    sds <- c(sds, sample_sd)
}

c(quantile(sds,.025), quantile(sds,.975))
(quantile(sds,.025) + quantile(sds,.975)) / 2

## 구간 추정공식을 이용한 결과를 확인. 모표준편차에 대한 구간 추정 공식을 생략
sqrt(var(y)*(n-1) / qchisq(.975,n-1))
sqrt(var(y)*(n-1) / qchisq(.025,n-1))

## 공식에 의한 값은 실제로 부트스트랩을 사용한 경우와 비교했을 떄에 큰 차이가 나지 않는다.
# 이는 각종 수학적 가정과 표본크기 등의 문제 때문에 복잡하니 생략하갰습니다.
# 중요한 것은 구간추정법을 모르는 대상도 점추정법만 알면 복원 추출을 통해서
# 구간 추정을 할 수 있다는 것이다. 이것이 바로 부트스트랩을 사용하는 이유가 된다.

