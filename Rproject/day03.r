## 확률
# 확률은 경우의 수에서 생각할 수 있는 모든 경우의 수 중에 우리 관심을 갖는 경우의 수가
# 차지하는 비율로 생각할 수 있다.

## ==용어==
## - 시행 : 다양한 결과가 나올 수 있는 어떤 것을 실제로 하는 것을 말함.
##          ex) 주사위를 던진다 , 복권을 긁는다, ...
## - 표본공간 : 가능한 모든 결과의 모임. 예) 동전 던지기의 경우 한번 던지면 (앞, 뒤)
##              두번 던지면 {(앞, 앞), (앞, 뒤), (뒤, 앞), (뒤, 뒤)}, 814만분의 1이 표본공간
## - 사건 : 가능한 결과들 중 어떤 요구사항을 만족하는 것, 
##          로또 복권 추첨 결과 "여섯개의 수가 연속이다", "모두 홀수가 나온다".. 등
##          중요한 것은 "사건"이 단 하나의 결과를 의미하지 않을 수 도 있다는 점...
## - 배반사건 : 동시에 일어날 수 없는 두 사건.  복권에서 "모두 짝수가 나온다"는 사건과
##              "모두 홀수가 나온다"는 사건은 동시에 일어날 수 없다는 사건 관계
## - 여사건 : 어떤 사건이 일어나지 않는 것을 말함.
##            복권 추첨결과가 "모든 숫자가 짝수다"의 여사건은 "모든 숫자가 짝수인 것은 아니다"
##            즉, "적어도 하나는 홀수이다."
## 수학적으로는 이들을 모두 집합으로 표현할 수 있다.
## 사건은 표본공간의 부분집합으로 정의, 공집합도 표본공간의 부분집합이기 때문에 사건..

### 수학적 확률
# 수학적인 확률은 어떤 가능한 모든 결과의 개수로 표현할 수 있다.
# 주사위를 두번 던졌을 경우 모든 경우의 수는 6*6 = 36 , "두 값을 곱했을 때 홀수가 나온다."
# 사건을 생각해보면 두 값을 곱했을 경우, 두 값 모두 홀수여야 한다. 이 때 경우의 수는 3*3 = 9
# 수학적 확률 계산 9/36 이것은 0.25가 됨을 알 수 있다. 
# 다만, 여기서 중요한 포인트는 표본공간의 모든 경우가 나올 수 있는 가능성은 같아야 한다.
# 이 조건이 만족되어야 한다.

### 통계적 확률
# 통계적 확률은 수학적 확률에 비해 더 구체적으로 접근한다. 통계적 확률은 "전체 시행 횟수
# 중 특정 사건이 일어나는 횟수의 비율로 표현"
# 특정 사건이 일어날 횟수를 r이라고 하면 그 사건이 일어날 비율은 r/n이 된다.
#   일반적으로 통계적 확률은 수학적 확률과 정확히 일치하지 않는다. 대신 횟수를 무한정
# 늘리면 통계적 확률은 결국 수학적 확률에 근접하게 된다.

### 극한의 의미
# 통계적 확률이 수학적 확률에 한없이 가까워 진다는 이야기는 시행 횟수가 무한정 늘어나는
# 극한을 가정하기 때문이다. 두가지 의미와 관련되어 있다.
#   첫번째, 시행횟수를 무한히 늘렸을 떄 , 수학적 확률에 통계적 확률이 근접합니다. 하지만,
# 시행 횟수가 적다면 우연에 의해서 수학적 확률에 벗어나는 경우가 종종 생긴다는 점이다.
# 통계학에서는 이것을 표집오차(Sampling Error)라고 합니다. 이것은 시행 횟수가 늘어날수록
# 점점 줄어드는 성질을 가지고 있다. 결국에는 0에 매우 가까워지게 된다는 점이다.
#   두번째, 한없이 가까워진다. 가까워진다는 말은 두 가지 의미를 포함한다. 수학적 확률과
# 통계적 확률간의 차이가 0에 가까워진다는 점이다. 단, 절대로 0이 된다는 것은 아님.

### 큰 수의 법칙
# 큰 수의 법칙(Law of large number)은 실제 자료의 값으로 계산한 평균. 즉, 표본평균이
# 자료의 크기 커짐에 따라서 한없이 특정 값에 가까워 진다는 것을 말함. 여기서 특정값은
# 확률용어로 기댓갑(Expected Value)를 말합니다.
# 통계적 확률은 큰 수의 법칙의 특수한 경우에 지나지 않는데 이유는 비율 자체가 일종의
# 표본 평균이기 때문입니다. 특정 값이 나오는 결과값의 합이 시행횟수로 나누면 이건 통계적
# 확률이 되고, 이것은 기록된 값의 평균이기도 한다.
#   애초에 평균이란 자료의 총합을 자료의 개수로 나눠준 것이기 때문이다. 즉, 큰수의 법칙이
# 적용된다는 것이다. 시행 횟수가 많아짐에 따라서 성공비율 또는 통계적 확률은 기대값에
# 가까워진다는 것을 알 수 있다. 여기서 말하는 기댓값은 수학적 확률을 의미함.

# 동전을 5회 던졌을 때의 경우 예
# 앞 : 1, 뒤 : 0
# 시행 값 : 1 0 0 0 1
# 총합 : 2
# 평균 : 2/5 = 0.4

# 동전을 20회 던졌을 때의 경우 예
# 앞 : 1, 뒤 : 0
# 시행 값 : 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1
# 총합 : 11
# 평균 : 11/20 = 0.55

## R을 이용한 시뮬레이션
# 동전 던지기 결과는 가능한 경우는 두가지, 앞면, 뒷면이고, 이 둘은 서로가 서로의
# 여사건 관계이다. 따라서 이들의 확률은 앞면이 나올 확률만 정하면, 뒷면이 나올 확률은
# 1에서 앞면이 나올 확률을 빼면 된다.
## 이때 확륙을 p라고 하면, 이렇게 가능한 결과는 두개 밖에 없고, 성공 확률이 정해져 있는
## 확률 시행을 "베르누이 시행(Bernoulli trial)"이라고 한다.

# R에서 사용하는 베르누이 시행 함수 rbinom()
# r의 의미는 랜덤을 의미함. R에서 확률적 난수를 생성하는 것을 의미하는 것으로 사용함.
# binom은 우리말로 이항이라고 번역되는 binomial단어의 축약형입니다.
# 베르누이 시행은 이항시행의 일종입니다. 차이는 베르누이 시행에서는 한번만,
# 이항 시행에서는 여러번 할 수 있다는 점입니다. 

## rbinom() 함수 형식
# rbinom(난수의 개수(시행 횟수의 결과), 값의 크기, 성공 확률)
# 난수 갯수는 난수의 갯수를 의미로 앞에 설명한 백터에 저장된다.
# 성공 확률은 0 과 1사이의 숫자를 사용함.

## 동전 던지기 : 5번 던진 결과 , 그 확률 0.5, 0은 실패 1은 성공
x <- rbinom(10000000, 1, 0.5)      # 시행 결과
mean(x)

### 수학적 확률로 확률 문제 풀기
# 문제, 1 ~ 5 까지 숫자 카드를 잘 섞어서 세장의 카드를 뽑아 세자리의 숫자를 만들 때에
# 그 결과가 320보다 클 확률은 얼마인가?

# 전제 조건 : 각각의 카드가 뽑힐 확률은 동일하다.

# 순열을 이용하여 계산... 조합(x)

# nPr, n = 5 , r = 3 => 5 x 4 x 3 = 60 : 전체 발생하는 경우의 수

# 이중에 우리가 원하는 경우의 수는 320보다 큰 수의 값을 가지는 경우.
# 앞 첫자리의 숫자는 3 ~ 5 이상이여야 조건에 충족된다. 
# 앞 첫자리가 숫자 4, 5는 뒤에 나오는 숫자와 상관없이 조건을 충족하게 된다.
# 각 4,5의 경우의 수 구하기 각각 경우의 수는 nPr => n = 4 , r = 2 ==> 4 x 3 =12
# 앞 첫자리가 3인 경우, 두번째 자리의 숫자가 1이 되면 안됨.(조건 충족x)
# 앞 첫자리가 3이고, 두번째 1일 경우의 수는 3이다. 전체 3일 때 경우수 - 두번째 1일경우
# 값은 9가 나온다. 이들을 정리하면 12 + 12 + 9 = 33

# 수학적 확률은 33/60으로 결과는 0.55가 된다.

### 통계적 확률로 문제 찾기 : 시뮬레이션
# 앞에 수학적 내용을 알지 못해도 풀 수 있는 방법이 존재한다.
# "시행 횟수가 늘어남에 따라 통계적 확률은 수학적 확률에 한없이 가까워 진다는 사실"
# 이 경우 장점은 모든 경우의 수를 다 검토해야 하는 수고를 하지 않을 수 있고,
# 특히 경우의 수를 세기가 매우 복잡한 문제에서 더 유용하게 사용된다.

## 시뮬레이션 시행은 R프로그램을 이용하여 1 ~ 5까지의 숫자 3개를 뽑아서 그 값이 320보다
## 큰 경우를 구하는 시뮬레이션을 진행할 수 있다. 이 시뮬레이션을 충분히 진행하여 비율을
## 계산하면 그게 통계적 확률이 되고, 이는 수학적 확률에 근사하게 된다.

## 수학적인 공식을 적용하지 않고 확률을 계산하는 방법을 "몬테카를로 시뮬레이션"
## "몬테카를로 방법"이라고 한다.

## 시행을 위해서 R에서 따로 프로그램을 하지 않아도 된다. sample()이라는 함수가 존재

## sample(추첨할 대상, 추첨할 개수, 복원 추출여부)
## ** 복원 추출은 뽑은 것을 원래대로 돌려 놓은 것을 말함. 여기서 비복원 추출을 한다.

## 여기서는 sample(1:5,3,replace=F) -> 1 ~ 5 까지 숫자를 3개 뽑아서 샘플을 작성(비복원)

n_simulation <- 2000
n_success <- 0

for (i in 1:n_simulation){
    x <- sample(1:5,3,replace = F)
    if (x[1] >= 4) {
        n_success <- n_success + 1
    }
    if ((x[1] == 3 ) & (x[2] >= 2)) {
        n_success <- n_success + 1
    }
}

print(n_success)
stc <- n_success / n_simulation

print(stc)

### 몬테카를로 방법을 사용하여 원주율 계산
## 원주율 : 3.14 ...
## 시뮬레이션을 통해서 원주율을 구하고, 실제 원주율과 비교...
## x축과 y축을 중심으로 2차원 좌표 평면을 생각합니다. 가로 축과 세로 축의 길이 1인
## 정사각형을 생각합니다. 이 정사각형의 원점을 중심으로 한 반지름이 1인 원을 그리면,
## 온전한 원이 아닌 원의 1/4인 4분원이 된다.
## 가로 세로 길이가 1인 정사각형에 매우 작은 입자를 뿌린다고 생각합니다.
## 이 경우에 4분원 안쪽에 떨어지는 것도 있고, 그렇지 않은 것도 있을 것입니다.
## 이 입자는 무작위로 뿌린다는 것을 가정하고, 4분원 안쪽에 뿌려진 입자의 비율과 정사각형의
## 넓이에서 사분원이 차지하는 넓이의 비율이라고 추측할 수 있다.
## 이 경우 오차가 생길 수 있으나, 입자를 충분히 많이 촘촘하게 뿌린다면, 통계적 확률은
## 수학적 확률에 가깝게 된다.
## 여기에 원 넓이를 구하는 식을 도입, 파이*반지름의 제곱 이걸 사분원이기 떄문에 1/4로 계산
## 결국 반지름이 1이기 때문에 파이/4 즉, 입자가 사분원 안에 떨어진 것들의 비율은
## 파이/4와 가깝게 된다. 구해진 값에 4를 곱하면 파이, 즉 원주율을 구할 수 있게 된다.

## R에서 이런 동작을 하는 함수 runif(1)
## 이 함수는 0에서 1사이의 무작위 숫자 하나를 선택, 이것을 좌표x,y에 대입하면
## 입자를 무작위로 뿌리는 것과 같은 효과를 가져올 수 있다.


n_sim <- 10000
x <- vector(length = n_sim)
y <- vector(length = n_sim)
res <- 0
for (i in 1:n_sim){
    x[i] <- runif(1)
    y[i] <- runif(1)
    if (x[i]^2 + y[i]^2 < 1){
        res <- res +1
    }
}
4 * res / n_sim

circle <- function(x) sqrt(1-x^2)
plot(x,y,xlab="X", ylab="Y")
curve(circle,from = 0, to = 1,add = T, col="Blue",lwd=3)

### 몬티홀 문제

## 바꾸지 않고 처음 문을 고른 경우
n_simul <- 1000
doors <- 1:3
success <- 0

for (i in 1:n_simul){
    # 세게의 문중 차의 위치를 선택
    car <- sample(doors,1)
    
    # 차가 없는 곳에 염소를 배치
    if (car == 1){
        goat <- c(2,3)
    }else if (car == 2){
        goat <- c(1,3)
    }else{
        goat <- c(1,2)
    }

    # 참가자가 문을 선택(고른다)
    pick <- sample(doors,1)

    # 참가자가 고르지 않은 문 중 염소가 있는 문을 찾는다
    goat_not_pick <- goat[goat != pick]

    # 참가자가 고르지 않은 문 중 염소가 있는 문 하나를 열어준다.
    if(length(goat_not_pick > 1)){
        open <- sample(goat_not_pick,1)
    }else {
       open <- goat_not_pick
    }
    
    # 바꾸지 않고 처음 고른 문이 차가 있는 문이면 "성공"을 기록
    if (pick == car) success <- success + 1
}

success/n_simul

# 바꾸는 경우
n_simul <- 1000
doors <- 1:3
success <- 0

for (i in 1:n_simul){
    # 세게의 문중 차의 위치를 선택
    car <- sample(doors,1)
    
    # 차가 없는 곳에 염소를 배치
    if (car == 1){
        goat <- c(2,3)
    }else if (car == 2){
        goat <- c(1,3)
    }else{
        goat <- c(1,2)
    }

    # 참가자가 문을 선택(고른다)
    pick <- sample(doors,1)

    # 참가자가 고르지 않은 문 중 염소가 있는 문을 찾는다
    goat_not_pick <- goat[goat != pick]

    # 참가자가 고르지 않은 문 중 염소가 있는 문 하나를 열어준다.
    if(length(goat_not_pick > 1)){
        open <- sample(goat_not_pick,1)
    }else {
       open <- goat_not_pick
    }
    
    # 바꾸어 선택한 문이 차가 있는 문이면 성공
    pick <- doors[(doors != pick) & (doors != open)]
    if(pick == car){
        success <- success + 1
    }
}

# 총 시행 중 "성공" 비율
success/n_simul

## 심슨의 역설

### 생일 역설 : 왜 드물게 보이는 사건은 꼭 일어나는가?
# 한번에 20명의 학생이 있을 떄에 생일이 겹치는 학생이 한명도 없을 확률은 얼마나 될까?
#
# (365 - 1)/365 * (365 - 2)/365 * (365 - 3)/365 * (365 - 4)/365 * (365 - 5)/365 ... * (365 -19)/365
# 결과는 약 58.9%


n <- 79
x <- 1

for (i in 1:(n-1)){
    x <- x * (365-i)/365 
}

print(x)